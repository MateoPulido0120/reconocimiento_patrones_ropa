{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Importación de las librerias utiles***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage import feature\n",
    "from PIL import Image \n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from skimage.io import imread_collection\n",
    "import tensorflow as tf\n",
    "from sklearn.cluster import KMeans\n",
    "import pywt\n",
    "from scipy.stats import gennorm\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Función para leer imágenes***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2image(data_list, size):\n",
    "    img_data = np.reshape(np.array(data_list), (size,size))\n",
    "    return  img_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Selección y limpieza de datos a clasificar (Camisetas y pantalones)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4    774\n",
      "1    509\n",
      "0    273\n",
      "2    228\n",
      "3    216\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_clothes = pd.read_csv('dataset2/images.csv')\n",
    "data_clothes['image'] = data_clothes['image'] + '.jpg'\n",
    "data_clothes = data_clothes[['image', 'label']]\n",
    "data_clothes_to_remove = ['T-Shirt', 'Pants', 'Shoes', 'Shorts', 'Dress']\n",
    "data_clothes = data_clothes[data_clothes['label'].isin(data_clothes_to_remove)]\n",
    "\n",
    "data_clothes = data_clothes[0:2000]\n",
    "\n",
    "\"\"\"\n",
    "T-Shirt  -> 4\n",
    "Pants    -> 1\n",
    "Shoes    -> 2\n",
    "Dress    -> 0\n",
    "Shorts   -> 3  \n",
    "\"\"\"\n",
    "label_encoder1 = preprocessing.LabelEncoder()\n",
    "data_clothes[\"label\"] = label_encoder1.fit_transform(data_clothes[\"label\"])\n",
    "\n",
    "# Classes and their counts within the dataset\n",
    "print(data_clothes['label'].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Funciones para almacenar los datos seleccionados a tratar***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_train_image():\n",
    "    k = 1\n",
    "    for i in tqdm(data_clothes.index.tolist()[0:1600]):\n",
    "        img_path = data_clothes['image'][i]\n",
    "        original_path = 'dataset2/images_original/' + img_path        \n",
    "        image =  Image.open(original_path)       \n",
    "        image = tf.image.resize(image, (224,224), preserve_aspect_ratio=False, antialias=False)  \n",
    "        image = tf.image.rgb_to_grayscale(image)\n",
    "        image  = tf.keras.utils.array_to_img(image) \n",
    "        new_path = 'dataset2/images_train/train' + str(k)  + '.jpg'\n",
    "        k += 1\n",
    "        if os.path.exists(new_path): \n",
    "            break\n",
    "        else:\n",
    "            image = image.save(new_path)\n",
    "\n",
    "def save_test_image():\n",
    "    k = 1\n",
    "    for i in tqdm(data_clothes.index.tolist()[1601:2000]):\n",
    "        img_path = data_clothes['image'][i]\n",
    "        original_path = 'dataset2/images_original/' + img_path        \n",
    "        image =  Image.open(original_path)   \n",
    "        image = tf.image.resize(image, (224,224), preserve_aspect_ratio=False, antialias=False)  \n",
    "        image = tf.image.rgb_to_grayscale(image)\n",
    "        image  = tf.keras.utils.array_to_img(image) \n",
    "        new_path = 'dataset2/images_test/test' + str(k) + '.jpg'\n",
    "        k += 1\n",
    "        if os.path.exists(new_path): \n",
    "            break\n",
    "        else:\n",
    "            image = image.save(new_path)   \n",
    "\n",
    "            \n",
    "def save_new_csv(path, data):\n",
    "    if os.path.exists(path): \n",
    "        pass\n",
    "    else:\n",
    "        data.to_csv(path, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Almacenamiento de los datos a tratar en carpetas a parte separando por nombres (train y test) y se crea un CSV con los datos a tratar***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1600/1600 [03:40<00:00,  7.25it/s]\n",
      "100%|██████████| 399/399 [00:52<00:00,  7.65it/s]\n"
     ]
    }
   ],
   "source": [
    "save_train_image()\n",
    "save_test_image()\n",
    "save_new_csv('dataset2/CSV/clothes.csv', data_clothes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
